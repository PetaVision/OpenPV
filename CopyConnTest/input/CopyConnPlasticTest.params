//
// CopyConnPlasticTest.params
//
// created by peteschultz: Nov 19, 2014
//

//  An input image is sent to two different layers, "OriginalConn Output"
//  and "CopyConn Output", using connections, an ordinary HyPerConn
//  and a CopyConn.
//  The Original connection  is normalized using normalizeSum with strength 1.
//  The CopyConn connection is normalized using normalizeSum with strength 2.
//  Thus, the values in OriginalConn Output should be twice those in
//  CopyConn Output
//  
//  This params file has sharedWeights set to true, and plasticity off.

debugParsing = false;    // Debug the reading of this parameter file.

HyPerCol "column" = {
   nx = 32;   //size of the whole networks
   ny = 32;
   dt = 1.0;  //time step in ms.
   dtAdaptFlag = false;  // If true, layers can provide HyPerCol info on acceptable timesteps and dt can be adjusted accordingly 
   randomSeed = 1538299561;  // Must be at least 8 digits long.  // if not set here,  clock time is used to generate seed
   startTime = 0.0;
   stopTime = 10.0;  
   errorOnNotANumber = true;
   progressInterval = 10.0; //Program will output its progress at each progressStep
   writeProgressToErr = false;  
   outputPath = "output/Plastic/";
   printParamsFilename = "pv.params"; // A record of the parameters used, including defaults and excluding unused params, will be written to this file.
   filenamesContainLayerNames = false;  
   filenamesContainConnectionNames = false;
   initializeFromCheckpointDir = "";
   checkpointWrite = false;
   suppressLastOutput = false; //If true, save the last output as checkpoint.
};

//
// layers
//

//All layers are subclasses of hyperlayer


// this is a input layer
Image "Input" = {
    nxScale = 1;  // this must be 2^n, n = ...,-2,-1,0,1,2,... 
    nyScale = 1;  // the scale is to decide how much area will be used as input. For exampel, nx * nxScale = 32. The size of input
    	      	  // cannot be larger than the input image size.
    imagePath = "input/sampleimage.png"; // it's a 32*32 image
    nf = 1; //number of features. For a grey image, it's 1. For a color image, it could be either 1 or 3.
    phase = 0; //phase defines an order in which layers should be executed.
    writeStep = -1;  //-1 means doesn't write for log
    sparseLayer = false; //only write weights which are not 0
    mirrorBCflag = false;    //border condition flag
    valueBC = 0.0;
    useImageBCflag = false;
    inverseFlag = false; 
    normalizeLuminanceFlag = false;
    autoResizeFlag = false;
    writeImages = false;
    offsetAnchor = "tl";
    offsetX = 0;  // offset for crop, when the input size is smaller than the size of image
    offsetY = 0;
    jitterFlag = false; // moving around like an eyeball. our eyeballs are not still even when we are gazing at something.
};

ANNLayer "OriginalConn Output" = {
    nxScale = 1; 
    nyScale = 1;
    nf = 8; // 8 output features 
    phase = 1;
    triggerFlag = false; // If true, layer updates in response to another layer updating.
    writeStep = 1.0;
    initialWriteTime = 0.0;
    mirrorBCflag = 1;
    sparseLayer = false;

    InitVType = "ConstantV";
    valueV = 1.0;

    //define a linear relation between its input and output, with some hard cut-off.
    VThresh = -infinity;   
    AMax = infinity;
    AMin = -infinity;
    AShift = 0.0;
    VWidth = 0.0;
};

ANNLayer "CopyConn Output" = {
    nxScale = 1; 
    nyScale = 1;
    nf = 8; // 8 output features 
    phase = 1;
    triggerFlag = false; // If true, layer updates in response to another layer updating.
    writeStep = 1.0;
    initialWriteTime = 0.0;
    mirrorBCflag = 1;
    sparseLayer = false;

    InitVType = "ConstantV";
    valueV = 1.0;

    //define a linear relation between its input and output, with some hard cut-off.
    VThresh = -infinity;   
    AMax = infinity;
    AMin = -infinity;
    AShift = 0.0;
    VWidth = 0.0;
};

//HyPerConns are connections between two layers

HyPerConn "OriginalConn" = {
    preLayerName = "Input";
    postLayerName = "OriginalConn Output";
    channelCode = 0;

// we have a 32*32 image, an input layer with nf = 1 and an output layer with nf = 8. So we have 32*32*8 outputs.
// the connection layer defines nxp * nyp (i.e. 7*7) edges from each pixel in input layer to 7*7 vertexs of 1 out of 8 images
// and these vertexs are chosen from the nearest ones around the pixel
    nxp = 7;
    nyp = 7;
    numAxonalArbors = 1;
    sharedWeights = true;
    writeStep = 1;
    initFromLastFlag = 0;
    
    weightInitType = "UniformRandomWeight";
    wMinInit = 1.0;
    wMaxInit = 2.0;
    sparseFraction = 0.0;
      
    strength = 1.0;  // 1.0 x post->num_neurons / pre->num_neurons
    normalizeMethod = "normalizeSum";
    normalizeOnInitialize = true;
    normalizeOnWeightUpdate = true;
    normalizeArborsIndividually = false;
    normalize_cutoff = 0;
    symmetrizeWeights = 0;
    preActivityIsNotRate = false;
    minSumTolerated = 0.0;
    normalizeFromPostPerspective = false;
    rMinX = 0.0;
    rMinY = 0.0;

    writeCompressedCheckpoints = false;
    plasticityFlag = true;

    delay = 0;

    pvpatchAccumulateType = "Convolve"; // "Convolve", "Stochastic", or "Maxpooling" (case-insensitive)
    shrinkPatches = false; // If only a small part of connections whose weights are non-zero, then we could shrink the whole networks
    updateGSynFromPostPerspective = false; // Whether receiving synaptic input should loop over pre-synaptic neurons (false) or post-synaptic neurons (true)
};

CopyConn "CopyConn" = {
    preLayerName = "Input";
    postLayerName = "CopyConn Output";
    channelCode = 0;
    delay = 0;
    
    writeStep = 1;
    writeCompressedCheckpoints = false;

    // CopyConn does not use a weight init method
    
    strength = 2.0;  // 1.0 x post->num_neurons / pre->num_neurons
    normalizeMethod = "normalizeSum";
    normalizeOnInitialize = true;
    normalizeOnWeightUpdate = true;
    normalizeArborsIndividually = false;
    normalize_cutoff = 0;
    symmetrizeWeights = 0;
    preActivityIsNotRate = false;
    minSumTolerated = 0.0;
    normalizeFromPostPerspective = false;
    rMinX = 0.0;
    rMinY = 0.0;
    
    pvpatchAccumulateType = "Convolve"; // "Convolve", "Stochastic", or "Maxpooling" (case-insensitive)
    shrinkPatches = false; // If only a small part of connections whose weights are non-zero, then we could shrink the whole networks
    updateGSynFromPostPerspective = false; // Whether receiving synaptic input should loop over pre-synaptic neurons (false) or post-synaptic neurons (true)
    
    originalConnName = "OriginalConn";
};
