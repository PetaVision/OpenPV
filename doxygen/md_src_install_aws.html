<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.8"/>
<title>PetaVision: AWS Installation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
</script>
<link rel="search" href="search-opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="PetaVision"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">PetaVision
   &#160;<span id="projectnumber">Alpha</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.8 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
          <div class="left">
            <form id="FSearchBox" action="search.php" method="get">
              <img id="MSearchSelect" src="search/mag.png" alt=""/>
              <input type="text" id="MSearchField" name="query" value="Search" size="20" accesskey="S" 
                     onfocus="searchBox.OnSearchFieldFocus(true)" 
                     onblur="searchBox.OnSearchFieldFocus(false)"/>
            </form>
          </div><div class="right"></div>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('md_src_install_aws.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">AWS Installation </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Welcome to the cloud. Here's everything you need to know about how to get your favorite run on Amazon's AWS services.</p>
<h1>Introduction</h1>
<p>Amazon AWS is a suite of tools to provide a virtual computing environment for end users. Here are the services we'll be using.</p>
<ul>
<li>EC2: Elastic Compute Cloud<ul>
<li>Allows you to create a virtual instance that run on Amazon hardware.</li>
</ul>
</li>
<li>EBS: Elastic Block Store<ul>
<li>The virtual hard drive that EC2 requires to do file I/O</li>
</ul>
</li>
<li>Snapshots<ul>
<li>A snapshot of an EBS is essentially a copy of that hard drive.</li>
</ul>
</li>
<li>AMI: Amazon Machine Image<ul>
<li>Snapshots can be converted to AMIs, which contain the operating system, tools, and in our case, the PetaVision toolbox.</li>
</ul>
</li>
<li>IAM: Identity and Access Management<ul>
<li>Amazon's user account control that allows for user accounts for one AWS account.</li>
</ul>
</li>
<li>S3: Simple Storage Service<ul>
<li>Long term shared storage. We don't have file io access to S3; everything must be downloaded/uploaded through https or AWS CLI. Databases and checkpoints will be stored here.</li>
</ul>
</li>
</ul>
<p>There exists a PetaVision AMI called 'PetaVision Public AMI' that has everything set up for PetaVision on GPUs. Additionally, the following software is installed on the image:</p><ul>
<li>Octave</li>
<li>Python</li>
<li>ffmpeg</li>
<li>emacs</li>
</ul>
<h1>Overview</h1>
<p>Here's a quick overview of how our instance is set up.</p><ul>
<li>GPU spot instance</li>
<li>10GB root EBS that contains the OS, PetaVision and all software.</li>
<li>50 - 100GB personal EBS that will store sandboxes and output files.</li>
<li>S3 for storing databases and checkpoints.</li>
</ul>
<p>Services that cost money:</p><ul>
<li>GPU Spot Instance: market price, usually between $.10 and $.15 per hour</li>
<li>EBS usage: $.10 per GB per Month</li>
<li>S3 usage: $.03 per GB per Month</li>
<li>Internet to EBS/S3 transfer: Free</li>
<li>EBS/S3 transfer to Internet: cents per GB</li>
<li>S3 to EBS and EBS to S3 transfers in the same region: Free</li>
</ul>
<p>We are currently using the Oregon region.</p>
<h1>First time initialization</h1>
<p>This section explains how to get a new user set up on the aws account to do runs.</p>
<h2>Activate your account</h2>
<p>To create an AWS account, go to <a href="http://aws.amazon.com">Amazon's AWS page</a> and click on Products.</p>
<p>If you are in Kenyon Lab, contact an account administrator to create and set up your account. You should get a user name and a temporary password starting up. Follow <a href="md_src_aws_pv_internal.html">these instructions</a> for setting up a user in the PetaVision account.</p>
<h2>Create your ssh key pair</h2>
<p>Each instance must have an ssh key for security. Here's how to generate your own.</p>
<p>Open a terminal and enter the following commands </p><pre class="fragment">cd ~/.ssh #Create it if it doesn't exist
ssh-keygen -t rsa
</pre><p>Follow the instructions on the screen. Note the filename in which you saved the key, ex: username_aws. </p><pre class="fragment">ssh-add ~/.ssh/username_aws
pbcopy &lt; ~/.ssh/username_aws.pub #Copies contents of username_aws.pub to your clipboard for macs
</pre><p>Go to the EC2 management page, and find the option Key Pairs under Network and Security in the left tab. Click Import Key Pair and paste the public key contents in. Click import.</p>
<p>Note that you may have to run ssh-add again if you get a public key error. To solve this, add this line to your <code>~/.bashrc</code> or <code>~/.profile</code>, replacing your private key name with username_aws </p><pre class="fragment">ssh-add ~/.ssh/username_aws
</pre><h1>Starting an Instance</h1>
<p>An AWS Instance allows the user to create a virtual environment to do runs. We do spot instances to save money, and already have the PetaVision capabilities to restart a run if it does die. For more information on spot instances, go to <a href="http://aws.amazon.com/ec2/purchasing-options/spot-instances/">http://aws.amazon.com/ec2/purchasing-options/spot-instances/</a>.</p>
<h2>Creating a Spot Instance</h2>
<p>If you intend to create a MPI Cluster of Instances jump to the bottom section</p>
<ul>
<li>Go to the EC2 management page. Click Instances under Instances in the left tab.</li>
<li>Step 1: Choose an Amazon Machine Image (AMI)<ul>
<li>Click Launch Instance. Click on Community AMIs in the left tab.</li>
<li>Using the search bar, find the AMI labeled <code>PetaVision Public AMI</code>. Click Select.</li>
</ul>
</li>
<li>Step 2: Choose an Instance Type<ul>
<li>Pick a GPU instance (g2.2xlarge). Click next.</li>
</ul>
</li>
<li>Step 3: Configure Instance Details<ul>
<li>If you are making only one instance, keep the number of instances at 1. (Note that there are additional steps involved if you are launching an mpi cluster of instances on this screen under the MPI Clusters section)</li>
<li>Check Request Spot Instances under Purchasing option</li>
<li>Pricing for an hour of an AWS instance comes from the dynamic market price determined by how many available spot instances there are and the lowest bid that still gets an instance. For more information about spot instances, you can read more here:<a href="http://aws.amazon.com/ec2/purchasing-options/spot-instances/">EC2 Spot Instance Pricing Information</a></li>
<li>You will see three different regions (a, b, c). We recommend you pick the least expensive region in Subnet. Next, enter your Maximum Price you are willing to pay to keep your instance. We recommend approximately $0.15 - $0.20 above the current price to insulate you from typical fluctuations in price. Remember that even if your bid is higher than the current price you will only pay the current price not your maximum price.</li>
<li>NOTE: If you want to see how the price typically fluctuates, you'll need to leave your current configuration or open a new tab, navigate back to EC2 &gt; Instances &gt; Spot Requests &gt; Pricing History. Select your instance type (eg. g2.2xlarge) and review the history.</li>
<li>Note the subnet since any EBS volume you attach has to be in the same subnet region</li>
<li>All of the remaining default values can be kept the same</li>
<li>Click next.</li>
</ul>
</li>
<li>Step 4: Add Storage<ul>
<li>No additional storage is required. Make sure Delete on Termination is checked. Click next.</li>
</ul>
</li>
<li>Step 5: Tag Instance<ul>
<li>Give your instance a name in the Value text box next to the Key name.</li>
<li>Click next.</li>
<li>(Note that there are additional steps involved if you are launching an mpi cluster of instances on this screen under the MPI Clusters section)</li>
</ul>
</li>
<li>Step 6: Configure Security Group<ul>
<li>Check <em>Select an existing security group</em>.</li>
<li>Select the default security group. Click Review and Launch.</li>
</ul>
</li>
<li>Step 7: Review Spot Instance Request<ul>
<li>After reviewing, click launch.</li>
<li>Select Choose an existing key pair, and select your key pair that you created earlier.</li>
<li>Check the acknowledgement, and click Request Spot Instance.</li>
</ul>
</li>
</ul>
<p>Spot instances will take a few minutes to fulfill. Looking under Instances in the left tab, you can see the status of your request. If you did not name your instance on Step 5, name the instance something relevant once the instance is started.</p>
<p>The PetaVision Public AMI already includes all the code and tools you will need to start a PetaVision run.</p>
<h1>Working with a running instance</h1>
<p>Now that you have an instance up, let's connect to it!</p>
<h2>SSH into your running instance</h2>
<p>To start working with your instance, you need to know the IP address of your instance:</p><ul>
<li>Go to the EC2 management page. Click Instances under Instances in the left tab.</li>
<li>Find your instance in the list and note the Public IP address of the instance.</li>
<li><p class="startli">To connect use the following command:</p>
<p class="startli">ssh ec2-user</p>
</li>
<li>NOTE: ec2-user is NOT a placeholder for you user name.</li>
</ul>
<h2>Copy data to your instance</h2>
<p>To start running experiments, you'll probably want some data to work with. If you have a dataset on your local machine you can use the following command in a new terminal window: </p><pre class="fragment">scp sourceFile ec2-user@public_ip_address:/destinationFile
</pre><p>Datasets hosted online can also be grabbed using wget. For example, the following command will download the CIFAR dataset: </p><pre class="fragment">wget "http://www.cs.toronto.edu/~kriz/cifar-10-matlab.tar.gz"
</pre><h2>Creating an EBS persistent volume</h2>
<p>AWS Spot Instances can die at any time. We will need an EBS persistent volume to store any run output we have as well as any sandboxes being ran from.</p>
<h3>Create your volume</h3>
<ul>
<li>Go to the EC2 management page. On the left, click Volumes under Elastic Block Store. Click Create Volume.</li>
<li>Adjust the size of the volume. 50 to 100 GB should be more than enough, depending on your run.</li>
<li>Select the same subnet availability zone as your running instance.</li>
<li>Click create.</li>
<li>It will take a few minutes to create the volume. Name it something appropriate.</li>
</ul>
<h3>Mounting your new volume to a running instance</h3>
<p>In order to use this volume in a running instance, we must mount it to a running instance.</p><ul>
<li>Go to the EC2 management page. On the left, click Volumes under Elastic Block Store.</li>
<li>Select the volume you want to attach. The state of the volume should say available.</li>
<li>Click actions, and select attach volume.</li>
<li>Click on the Instance box and select your running instance.</li>
<li>Make sure the device is set to <code>/dev/sdf</code>. This is the default value.</li>
</ul>
<p>A new EBS volume is completely blank. That means we need to format the volume to our instance filesystem. Note that this needs to be done only once per new volume.</p><ul>
<li><p class="startli">Connect to your running instance.</p>
<p class="startli">sudo mkfs -t ext4 /dev/sdf</p>
</li>
</ul>
<h2>Setting up PetaVision</h2>
<p>Because the instance was booted from a PetaVision AMI, all of PetaVision should already exist in the home directory. There are several things needed to be done for PetaVision setup.</p>
<p>If you want to download a new copy of PetaVision because you are a developer: svn co <a href="https://sourceForgeUserName@svn.code.sf.net/p/petavision/code/trunk">https://sourceForgeUserName@svn.code.sf.net/p/petavision/code/trunk</a> PetaVision svn co <a href="https://sourceForgeUserNamesvn.code.sf.net/p/petavision/code/PVSystemTests">https://sourceForgeUserNamesvn.code.sf.net/p/petavision/code/PVSystemTests</a> PVSystemTests (this is a standard sandbox useful for checking PetaVision)</p>
<h3>Accessing your mounted volume in a running instance</h3>
<ul>
<li>Connect to your running instance</li>
<li>Run the file <code>~/startup.sh</code><ul>
<li>This will do 2 things: mount your data to the directory <code>~/mountData</code> and update PetaVision and PVSystemTests.</li>
<li>Make sure you followed the steps for attaching and formatting a drive listed above, otherwise your EBS volume will not attach correctly</li>
</ul>
</li>
</ul>
<h3>Setting up your sandbox in your persistent volume</h3>
<ul>
<li>cd to mountData.</li>
<li>Check out any sandboxes that you are planning on using. Ex: <pre class="fragment">  svn co http://svn.code.sf.net/p/petavision/code/sandbox/HyPerHLCA HyPerHLCA            (this is read only)
</pre></li>
<li>cd to ~/workspace.</li>
<li>Edit CMakeLists.txt using your favorite command-line text editor. (eg. vim or emacs)</li>
<li>At the end of the file, add the absolute path to your sandbox to the cmakelists. Ex: <pre class="fragment">  add_subdirectory(/home/ec2-user/mountData/HyPerHLCA /home/ec2-user/mountData/HyPerHLCA)
</pre></li>
</ul>
<p>Note that the same directory is put twice into the command add_subdirectory.</p>
<h3>Building PetaVision</h3>
<pre class="fragment">cd ~/workspace.
ccmake . 
</pre><p>Most of these variables should already be set up, but here are the important ones:</p><ul>
<li>CMAKE_BUILD_TYPE: Release</li>
<li>CUDA_GPU: True</li>
<li>CUDA_RELEASE: True</li>
<li>CUDNN: True</li>
<li>CUDNN_PATH: /home/ec2-user/cuDNN/cudnn-6.5-linux-x64-R2-rc1u</li>
<li>Open_MP_THREADS: True</li>
</ul>
<p>Press c to configure. Press e to exit the print statements. Repeat until the g option appears and press g. cd to your sandbox and run <code>make -j 8</code></p>
<h1>Optional Configuration Details</h1>
<p>You've reached the end of the main installation instructions. If you want to store you data on an S3 server or set up MPI-linked instances, follow the instructions below.</p>
<h2>S3</h2>
<p>S3 is long term storage for amazon's cloud. S3 objects (files, images) can only be accessed through http, but is much cheaper than ebs volumes. For the most part, you can skip this step to get started, but you can save a lot of money if you keep your datasets and results on S3</p>
<h3>Create your access key</h3>
<ul>
<li>Go to the Identity &amp; Access Management page from the main AWS dashboard. On the left, click users.</li>
<li>Select your account and click user actions.</li>
<li>Select Manage Access Keys.</li>
<li>Click create access key. Click Download Credentials and open the file. You will need the access key and secret access key.</li>
</ul>
<h3>Create your bucket</h3>
<ul>
<li>Go to the S3 management page.</li>
<li>See if your database is already there (such as kitti or neovision2heli datasets). If they are, you are done.</li>
<li>On the top, click Create Bucket.</li>
<li>Name your bucket something appropriate.</li>
<li>Make sure your region is the same as your ec2 users. Transferring from region to region costs money.</li>
<li>Click create.</li>
</ul>
<h3>S3 Setup</h3>
<ul>
<li>SSH into your running instance.</li>
<li>Enter the following command: aws configure</li>
<li>Enter your access key and secret access key. The rest can be left blank.</li>
</ul>
<h2>S3 Transfer</h2>
<p>There are several ways to upload data to S3 to an existing bucket.</p>
<h3>EBS Volume to S3 (preferred)</h3>
<ul>
<li>Getting your database on S3:</li>
<li>Download your database, most likely to mountData. Make sure your EBS volume is big enough to store all of the database.</li>
<li><p class="startli">cd to the outer directory of your database.</p>
<p class="startli">aws s3 cp &ndash;recursive myDatabaseFolder s3://yourBin/myDatabaseFolder</p>
</li>
<li>Note that you must put myDatabaseFolder on both the destination and source to keep the directory structure on s3.</li>
<li>Optional: Make sure you have all of your database on s3. Run the same command as above except for sync instead of cp.</li>
<li>Once the data is on s3, you can delete the local data off the EBS volume.</li>
</ul>
<h3>Local to S3</h3>
<ul>
<li>Go to the S3 management page.</li>
<li>Click an existing bucket that you would like your dataset to be, or create one and enter the bucket.</li>
<li>Click upload.</li>
<li>Drag the folder you would like to upload to the window.</li>
<li>Click start upload.</li>
</ul>
<p>Once you have your data on S3, you can specify a list of urls to feed to PetaVision Movie layer. As an example: </p><pre class="fragment">s3://myBin/myDatabaseFolder/img00.png
s3://myBin/myDatabaseFolder/img01.png
s3://myBin/myDatabaseFolder/img02.png
</pre><h3>PetaVision Parameter Changes</h3>
<p>Here are the changes you need to make to your parameter file.</p><ul>
<li>In your movie layers, make sure your list of filenames is a list of s3 urls.</li>
<li>Change your output directory to somewhere in mountData.</li>
<li>Future work will be done to get checkpoints on s3.</li>
</ul>
<h2>MPI Clusters</h2>
<p>This section explains how to set up a cluster of instances to do a PetaVision run across multiple instances. Most of the instructions are the same, with several difference when launching instances:</p>
<h3>Configure Instance Details screen</h3>
<ul>
<li>Set number of instances to the number of instances you would like to use in the cluster.</li>
<li>Under Placement Group, create or select a placement group. All instance under one placement group have extra bandwidth between the nodes.<ul>
<li>Note: If you chose an existing placement group, it must be in the same availability zone that you are requesting for the instance (e.g., "us-west-2a").</li>
</ul>
</li>
</ul>
<h3>Configure Security Group screen</h3>
<p>When selecting an existing security group, use MPI_security instead of the default security group. This allows each instance to accept inbound data from other instances using this security group ID.</p>
<h3>Specific MPI cluster setup</h3>
<ul>
<li>On your local machine, navigate to <code>petavision_trunk/docs/AWS/</code></li>
<li>Edit the file <code>hosts</code></li>
<li>Leave the first line alone. Add the external ip address for every node in your cluster. node0 will be your root node, the instance you will be launching everything from.</li>
<li>Edit the file nodefile. Add each additional node you added to hosts, with the number of mpi processes you would like to run on as <code>slots</code></li>
<li>Run setup.sh in this directory on your local machine. This will move all the nessessary ssh keys to the clusters, as well as adding every node in the cluster into hosts.<ul>
<li>This script will update and build PetaVision.</li>
</ul>
</li>
<li>ssh into your root node (node0).</li>
<li>Follow the instructions to mount your EBS drive to your root node. Note that only the root node does any file io, so the root node is the only node that you need to attach and mount your volume to.</li>
<li>Build your sandbox executable on the root node. Copy and move your sandbox executable somewhere <em>NOT</em> in your attached EBS volume (for example, in your home directory).</li>
<li><p class="startli">Copy your executable to all nodes to your cluster. To do this, run the following from your home directory:</p>
<p class="startli">sh cpCluster.sh path_to_executable</p>
</li>
</ul>
<p>To run from your root node, use the following command: </p><pre class="fragment">mpirun -np num_processors -hostfile ~/nodefile --bind-to none path_to_executable petavision_parameters
</pre><p>The <code>--bind-to none</code> flag is nessessary to get full threading utilization on aws. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.8 </li>
  </ul>
</div>
</body>
</html>
